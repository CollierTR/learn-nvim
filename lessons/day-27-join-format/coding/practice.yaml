# Line Formatting Practice File
# Practice using J to join lines and gq to format long lines
# This file contains intentionally long lines that need formatting

# Long connection strings that should be broken up
database_connections:
  primary: "postgresql://app_user:secure_database_password_with_special_characters_123@postgres-primary.database.svc.cluster.local:5432/production_database?sslmode=require&connect_timeout=30&application_name=microservice-api&pool_min_conns=5&pool_max_conns=20&pool_max_conn_lifetime=1h&pool_max_conn_idle_time=30m&pool_health_check_period=1m&statement_timeout=60s&lock_timeout=30s&idle_in_transaction_session_timeout=300s"

  replica: "postgresql://readonly_user:readonly_database_password_with_numbers_456@postgres-replica.database.svc.cluster.local:5432/production_database?sslmode=prefer&connect_timeout=15&application_name=microservice-readonly&pool_min_conns=2&pool_max_conns=10&pool_max_conn_lifetime=30m&pool_max_conn_idle_time=15m&default_transaction_isolation=read_committed&target_session_attrs=read-only"

# Long cache configuration strings
cache_connections:
  redis_cluster: "redis://default:super_secure_redis_password_with_special_symbols@redis-cluster.cache.svc.cluster.local:6379/0?pool_size=20&timeout=2s&retry_on_timeout=true&health_check_interval=30s&max_retries=3&retry_delay=100ms&idle_timeout=300s&read_timeout=10s&write_timeout=10s&connect_timeout=5s&sentinel_timeout=10s&cluster_retries=3&cluster_retry_delay=500ms"

  memcached: "memcached://memcached-cluster.cache.svc.cluster.local:11211?pool_size=10&timeout=1s&retry_attempts=2&binary_protocol=true&tcp_nodelay=true&failure_behavior=redistribute&hash_strategy=consistent&distribution=consistent_ketama&remove_failed_servers=true&retry_timeout=30s&dead_timeout=60s"

# Extremely long API endpoint URLs
api_endpoints:
  user_management: "GET /api/v2/users?page=1&limit=50&sort=created_at&order=desc&filter[status]=active&filter[role]=developer&filter[department]=engineering&include=profile,permissions,last_login,activity_log&fields[users]=id,username,email,first_name,last_name,created_at,updated_at,last_login_at&fields[profile]=bio,avatar_url,phone,address,timezone&fields[permissions]=name,scope,resource,granted_at&search=john&date_from=2024-01-01T00:00:00Z&date_to=2024-12-31T23:59:59Z&format=json&api_version=2.1&client_id=web_application&request_id=req_123456789"

  order_processing: "POST /api/v2/orders/{order_id}/process?validate_payment=true&send_confirmation_email=true&update_inventory_levels=true&calculate_taxes_and_fees=true&apply_discount_codes=true&check_fraud_detection=true&verify_shipping_address=true&schedule_delivery_date=true&notify_customer_via_sms=true&log_analytics_events=true&sync_with_crm_system=true&update_loyalty_points=true&generate_pdf_invoice=true&backup_order_data=true&create_audit_trail=true&run_compliance_checks=true&idempotency_key=idem_987654321&timeout=30000&retry_attempts=3&callback_url=https://api.company.com/webhooks/order-processed"

# Long configuration blocks that should be reformatted
monitoring_configuration:
  prometheus_scrape_config: "job_name=kubernetes-pods,kubernetes_sd_configs=[{role=pod,namespaces={names=[default,monitoring,logging,ingress]}}],relabel_configs=[{source_labels=[__meta_kubernetes_pod_annotation_prometheus_io_scrape],action=keep,regex=true},{source_labels=[__meta_kubernetes_pod_annotation_prometheus_io_path],action=replace,target_label=__metrics_path__,regex=(.+)},{source_labels=[__address__,__meta_kubernetes_pod_annotation_prometheus_io_port],action=replace,regex=([^:]+)(?::\\d+)?;(\\d+),target_label=__address__,replacement=${1}:${2}},{action=labelmap,regex=__meta_kubernetes_pod_label_(.+)},{source_labels=[__meta_kubernetes_namespace],action=replace,target_label=kubernetes_namespace},{source_labels=[__meta_kubernetes_pod_name],action=replace,target_label=kubernetes_pod_name}]"

  grafana_dashboard_query: "sum(rate(http_requests_total{job=\"kubernetes-pods\",kubernetes_namespace=\"production\",method=~\"GET|POST|PUT|DELETE\",status=~\"2..|3..|4..|5..\"}[5m])) by (kubernetes_pod_name, method, status) / sum(rate(http_requests_total{job=\"kubernetes-pods\",kubernetes_namespace=\"production\",method=~\"GET|POST|PUT|DELETE\"}[5m])) by (kubernetes_pod_name, method) * 100"

# Docker and Kubernetes command lines that are too long
deployment_commands:
  docker_run: "docker run --detach --name microservice-application --restart unless-stopped --network application-network --env-file .env.production --volume /var/log/application:/app/logs --volume /etc/ssl/certificates:/app/certificates:readonly --volume /app/configuration:/app/config:readonly --publish 8080:8080 --publish 9090:9090 --publish 8443:8443 --memory 4g --cpus 2.0 --health-cmd 'curl --fail --silent http://localhost:8080/health/live || exit 1' --health-interval 30s --health-timeout 10s --health-retries 3 --health-start-period 60s --label app=microservice --label version=2.1.0 --label environment=production --label team=platform-engineering company/microservice-application:v2.1.0"

  kubectl_apply: "kubectl apply --filename deployment.yaml --filename service.yaml --filename configmap.yaml --filename secret.yaml --filename ingress.yaml --filename horizontalpodautoscaler.yaml --filename poddisruptionbudget.yaml --filename networkpolicy.yaml --filename serviceaccount.yaml --filename role.yaml --filename rolebinding.yaml --namespace production --validate true --dry-run client --output yaml --record true --wait true --timeout 600s --force false --grace-period 30 --cascade background --field-manager kubectl-apply"

# Environment variable strings that are concatenated
environment_configurations:
  production_vars: "NODE_ENV=production,PORT=8080,HOST=0.0.0.0,API_BASE_URL=https://api.company.com,DATABASE_URL=postgresql://prod_user:prod_password@postgres-prod.database.local:5432/production_db?sslmode=require,REDIS_URL=redis://default:prod_redis_password@redis-prod.cache.local:6379/0,JWT_SECRET=super_secure_jwt_secret_key_for_production_environment_do_not_share,STRIPE_API_KEY=sk_live_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,SENDGRID_API_KEY=SG.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,TWILIO_AUTH_TOKEN=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,AWS_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXX,AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,AWS_REGION=us-west-2,S3_BUCKET_NAME=company-production-assets-bucket,CLOUDFRONT_DISTRIBUTION_ID=EXXXXXXXXXXXXX,SENTRY_DSN=https://xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx@sentry.io/xxxxxxx"

  staging_vars: "NODE_ENV=staging,PORT=8080,HOST=0.0.0.0,API_BASE_URL=https://api-staging.company.com,DATABASE_URL=postgresql://staging_user:staging_password@postgres-staging.database.local:5432/staging_db?sslmode=prefer,REDIS_URL=redis://default:staging_redis_password@redis-staging.cache.local:6379/1,JWT_SECRET=staging_jwt_secret_key_for_testing_environment_only,STRIPE_API_KEY=sk_test_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,SENDGRID_API_KEY=SG.test_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx,LOG_LEVEL=debug,METRICS_ENABLED=true,TRACING_ENABLED=true,PROFILING_ENABLED=true,DEBUG_MODE=true,CORS_ORIGINS=https://app-staging.company.com,https://admin-staging.company.com,RATE_LIMITING_ENABLED=false,CACHE_ENABLED=true,SESSION_TIMEOUT=3600"

# Infrastructure as Code configurations with long parameter lists
terraform_configurations:
  vpc_module: "module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" version = \"~> 3.0\" name = \"production-vpc\" cidr = \"10.0.0.0/16\" azs = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"] private_subnets = [\"10.0.1.0/24\", \"10.0.2.0/24\", \"10.0.3.0/24\"] public_subnets = [\"10.0.101.0/24\", \"10.0.102.0/24\", \"10.0.103.0/24\"] database_subnets = [\"10.0.201.0/24\", \"10.0.202.0/24\", \"10.0.203.0/24\"] enable_nat_gateway = true enable_vpn_gateway = false enable_dns_hostnames = true enable_dns_support = true enable_flow_log = true flow_log_destination_type = \"cloud-watch-logs\" create_flow_log_cloudwatch_log_group = true create_flow_log_cloudwatch_iam_role = true tags = { Terraform = \"true\" Environment = \"production\" Team = \"platform-engineering\" CostCenter = \"infrastructure\" } }"

  eks_module: "module \"eks\" { source = \"terraform-aws-modules/eks/aws\" version = \"~> 19.0\" cluster_name = \"production-cluster\" cluster_version = \"1.28\" cluster_endpoint_private_access = true cluster_endpoint_public_access = true cluster_endpoint_public_access_cidrs = [\"0.0.0.0/0\"] vpc_id = module.vpc.vpc_id subnet_ids = module.vpc.private_subnets enable_irsa = true eks_managed_node_groups = { general = { min_size = 3 max_size = 20 desired_size = 10 instance_types = [\"t3.large\"] capacity_type = \"ON_DEMAND\" ami_type = \"AL2_x86_64\" disk_size = 50 disk_type = \"gp3\" disk_encrypted = true ebs_optimized = true monitoring = { enabled = true } labels = { Environment = \"production\" NodeGroup = \"general\" } tags = { ExtraTag = \"general-workers\" } } } tags = { Terraform = \"true\" Environment = \"production\" } }"

# Network and security configurations
security_configurations:
  network_policy_spec: "apiVersion: networking.k8s.io/v1,kind: NetworkPolicy,metadata: {name: comprehensive-network-policy, namespace: production},spec: {podSelector: {matchLabels: {app: microservice, tier: backend}}, policyTypes: [Ingress, Egress], ingress: [{from: [{podSelector: {matchLabels: {app: frontend}}}, {podSelector: {matchLabels: {app: api-gateway}}}, {namespaceSelector: {matchLabels: {name: monitoring}}}], ports: [{protocol: TCP, port: 8080}, {protocol: TCP, port: 8443}, {protocol: TCP, port: 9090}]}], egress: [{to: [{podSelector: {matchLabels: {app: database}}}, {podSelector: {matchLabels: {app: cache}}}], ports: [{protocol: TCP, port: 5432}, {protocol: TCP, port: 6379}]}, {to: [], ports: [{protocol: UDP, port: 53}, {protocol: TCP, port: 53}]}]}"

  rbac_policy_definition: "apiVersion: rbac.authorization.k8s.io/v1,kind: ClusterRole,metadata: {name: comprehensive-cluster-role},rules: [{apiGroups: [\"\", \"apps\", \"extensions\", \"networking.k8s.io\", \"policy\", \"rbac.authorization.k8s.io\"], resources: [\"pods\", \"services\", \"deployments\", \"replicasets\", \"configmaps\", \"secrets\", \"ingresses\", \"networkpolicies\", \"poddisruptionbudgets\", \"roles\", \"rolebindings\", \"serviceaccounts\"], verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]}, {apiGroups: [\"metrics.k8s.io\"], resources: [\"pods\", \"nodes\"], verbs: [\"get\", \"list\"]}, {apiGroups: [\"autoscaling\"], resources: [\"horizontalpodautoscalers\"], verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]}]"

# Monitoring and logging configurations with long queries
observability_configurations:
  prometheus_alert_rules: "groups: [{name: critical-alerts, rules: [{alert: HighErrorRate, expr: \"sum(rate(http_requests_total{status=~\\\"5..\\\"}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service) > 0.1\", for: 2m, labels: {severity: critical}, annotations: {summary: \"High error rate detected\", description: \"Service {{ $labels.service }} has error rate above 10% for more than 2 minutes\"}}, {alert: HighLatency, expr: \"histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)) > 0.5\", for: 5m, labels: {severity: warning}, annotations: {summary: \"High latency detected\", description: \"Service {{ $labels.service }} has 95th percentile latency above 500ms\"}}]}, {name: resource-alerts, rules: [{alert: HighCPUUsage, expr: \"100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100) > 80\", for: 5m, labels: {severity: warning}, annotations: {summary: \"High CPU usage\", description: \"Instance {{ $labels.instance }} has CPU usage above 80%\"}}]}]"

  elasticsearch_query: "query: {bool: {must: [{range: {timestamp: {gte: \"now-1h\", lte: \"now\"}}}, {term: {level: \"error\"}}, {wildcard: {message: \"*database*\"}}], should: [{match: {service: \"user-service\"}}, {match: {service: \"order-service\"}}], minimum_should_match: 1, filter: [{terms: {kubernetes.namespace: [\"production\", \"staging\"]}}, {exists: {field: \"correlation_id\"}}]}}, aggs: {services: {terms: {field: \"service.keyword\", size: 10}, aggs: {error_count: {value_count: {field: \"message\"}}, avg_response_time: {avg: {field: \"response_time\"}}}}, error_trends: {date_histogram: {field: \"timestamp\", calendar_interval: \"5m\"}, aggs: {error_rate: {rate: {field: \"level\", unit: \"minute\"}}}}}"